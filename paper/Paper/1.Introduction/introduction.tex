Machine learning has many applications. Since its discovery in the 1950s, machine learning has been used to solve complex problems in various domains. In the 1990s the focus of machine learning shifted from a knowledge-driven approach to a data-driven approach \cite{marr2016short}. This is when scientists started using machine learning to analyze large amounts of data and draw conclusions from the results \cite{marr2016short}. One of the problems with this, is that it takes a lot of computing power to process data at this scale. In present time, this problem is amplified by the fact, that Python is the programming language, which has the best support for machine learning algorithms, through its large amount of libraries and user friendly syntax. This creates a problem when it comes to low consumption devices. If you have a low consumption device, which has low computing power and limited battery capacity, running machine learning inference can be a demanding task on the device's hardware. This can be combatted by using simple algorithms, which requires less computations and by implementing the algorithm in a low level language.\fxnote{Add introduction section to existing solutions with references. Discuss the issues.}